- [Тестовое задание](#тестовое-задание)
- [Реализация](#реализация)

# Тестовое задание 

### Тестовое задание 
Используя фреймворк Scrapy необходимо написать парсер для получения информации о товарах интернет-магазина из списка категорий по заранее заданному шаблону, информация должна быть структурирована в виде словарей согласно формату выходных данных и сохранена в файл формата json.
На вход подается список категорий в виде ссылок (минимум 3), с количеством товаров от 100 штук на категорию
на сайте alkoteka.com (Например: https://alkoteka.com/catalog/slaboalkogolnye-napitki-2)
Обязательно осуществлять сбор данных с учетом выбранного региона для парсинга - Краснодар
По возможности для получения информации добавить возможность использовать подключение через прокси
### Входные данные
Изменяемый список ссылок на категории, можно выполнить в одном из двух вариантов:
<br>В виде константной переменной формата: START_URLS = ["url_1", "url_2", ..., "url_3"]
<br>В виде отдельного файла, который будет содержать список ссылок в произвольном формате

*** Обратите внимание, что тестовое задание выполняется только на Scrapy (без использования  Playwright, Headless, Selenium и тд)
### Входные данные
Формат выходных данных для одного товара:
На следующей странице вы увидите  общий шаблон формата данных, и он не учитывает особенности сайта, выбранного для задания. 

Если вы не смогли найти какие-то данные во время анализа сайта, все поля все равно должны быть собраны согласно стандартным значениям, так как являются обязательными для корректной проверки.
```
{
    "timestamp": int,  # Дата и время сбора товара в формате timestamp.
    "RPC": "str",  # Уникальный код товара.
    "url": "str",  # Ссылка на страницу товара.
    "title": "str",  # Заголовок/название товара (! Если в карточке товара указан цвет или объем, но их нет в названии, необходимо добавить их в title в формате: "{Название}, {Цвет или Объем}").
    "marketing_tags": ["str"],  # Список маркетинговых тэгов, например: ['Популярный', 'Акция', 'Подарок']. Если тэг представлен в виде изображения собирать его не нужно.
    "brand": "str",  # Бренд товара.
    "section": ["str"],  # Иерархия разделов, например: ['Игрушки', 'Развивающие и интерактивные игрушки', 'Интерактивные игрушки'].
    "price_data": {
        "current": float,  # Цена со скидкой, если скидки нет то = original.
        "original": float,  # Оригинальная цена.
        "sale_tag": "str"  # Если есть скидка на товар то необходимо вычислить процент скидки и записать формате: "Скидка {discount_percentage}%".
    },
    "stock": {
        "in_stock": bool,  # Есть товар в наличии в магазине или нет.
        "count": int  # Если есть возможность получить информацию о количестве оставшегося товара в наличии, иначе 0.
    },
    "assets": {
        "main_image": "str",  # Ссылка на основное изображение товара.
        "set_images": ["str"],  # Список ссылок на все изображения товара.
        "view360": ["str"],  # Список ссылок на изображения в формате 360.
        "video": ["str"]  # Список ссылок на видео/видеообложки товара.
    },
    "metadata": {
        "__description": "str",  # Описание товара
        "KEY": "str",
        "KEY": "str",
        "KEY": "str"
        # Также в metadata необходимо добавить все характеристики товара которые могут быть на странице.
        # Например: Артикул, Код товара, Цвет, Объем, Страна производитель и т.д.
        # Где KEY - наименование характеристики.
    }
    "variants": int,  # Кол-во вариантов у товара в карточке (За вариант считать только цвет или объем/масса. Размер у одежды или обуви варинтами не считаются).
}
```
### Ожидаемый результат

Результатом выполненного задания ожидается парсер который можно запустить командой
```
scrapy crawl spider_name -O result.json
```
После отработки парсера должен быть результирующий файл с собранными данными товаров по заданным категориям в формате, установленным согласно выходным данным.
<br>Плюсом будет использование прокси (хотя бы прокидывание в запросы бесплатных прокси)
<br>Плюсом будет сбор данных по заданному региону (могут отличаться цены, наличие и прочие данные для сайта)
<br>Чем больше навыков Вы продемонстрируете в тестовом задании, тем лучше. (ООП/прокси/middleware)

*** Обратите внимание, что тестовое задание выполняется только на Scrapy (без использования  Playwright, Headless, Selenium и тд)
 

# Реализация

Просмотрев все запросы, которые делает сайт https://alkoteka.com я нашла запросы к их API.
<br>Изменения в API происходят значительно реже, чем изменения в html, поэтому я выбираю сканировать API, а не html.

### Ссылки, которые сканируем
* Города - https://alkoteka.com/web-api/v1/city?page=1
* Листы (список товаров по выбранному городу) - https://alkoteka.com/web-api/v1/product?city_uuid=cba441ca-80fd-11e8-80f0-00155d2fc707&page=1&per_page=20&root_category_slug=krepkiy-alkogol
* Карточки (подробная информация по каждому товару) - https://alkoteka.com/web-api/v1/product/paulaner-myunkhenskoe-khel_86315?city_uuid=cba441ca-80fd-11e8-80f0-00155d2fc707

### Запуск кравлера
```
scrapy crawl scan_alkoteka -a city_name="Ленинградская ст-ца"
```
city_name - имя города в варианте написания как на сайте https://alkoteka.com/

Так как в выходных данных нет поля для хранения гео-локации, сканировать по-умолчанию все подряд города нет смысла.
Поэтому при запуске всегда указываем город, для которого хотим получить данные.

### Логика кравлера
* Получаем uuid города по названию, которое передали при запуске, по ссылке https://alkoteka.com/web-api/v1/city
* Берем uuid города и категории, указанные в переменной FACETS, и формируем ссылки на листы.
Например, https://alkoteka.com/web-api/v1/product?city_uuid=396df2b5-7b2b-11eb-80cd-00155d039009&options%5Bcategories%5D[]=sidr-medovukha&page=1&per_page=20&root_category_slug=slaboalkogolnye-napitki-2
* Парсим листы, формируем ссылки на карточки.
Например, https://alkoteka.com/web-api/v1/product/paulaner-myunkhenskoe-khel_86315?city_uuid=cba441ca-80fd-11e8-80f0-00155d2fc707
* Сохраняем исходные данные карточек в файл source.json
<br>В случае некорректной обработки нам нужно знать - а что именно мы отсканировали в момент возникновения бага, поэтому я сохраняю сорсы. 
* Сохраняем обработанные итоговые данные в файл result.json

### Пример итоговых данных
* Карточка на сайте (Ленинградская ст-ца) - https://alkoteka.com/product/vodka-1/organik-spelta_97096
* Карточка в выдаче API (Ленинградская ст-ца) - https://alkoteka.com/web-api/v1/product/organik-spelta_97096?city_uuid=cba441ca-80fd-11e8-80f0-00155d2fc707
* Итоговый JSON
```
{
    "timestamp": 1751454923338,
    "RPC": 97096,
    "url": "https://alkoteka.com/product/vodka-1/organik-spelta_97096",
    "title": "Водка, Органик Спельта, 0.5 Л",
    "marketing_tags": [
        "Скидка"
    ],
    "brand": "Органик",
    "section": [
        "Главная",
        "Крепкий алкоголь",
        "Органик Спельта"
    ],
    "price_data": {
        "current": 475,
        "original": 559,
        "sale_tag": "Скидка 16%"
    },
    "stock": {
        "in_stock": true,
        "count": 4
    },
    "assets": {
        "main_image": "https://web.alkoteka.com/storage/product/01/6a/97096_image.png",
        "set_images": [
            "https://web.alkoteka.com/storage/product/01/6a/97096_image.png"
        ],
        "view360": [],
        "video": []
    },
    "metadata": {
        "vid": "Водка классическая",
        "proizvoditel": "Пермалко",
        "brend": "Органик",
        "obem": "0.5 л.",
        "krepost": "40 %",
        "strana": "Россия",
        "temperatura-podaci": "6–8 °C",
        "__description": "Аромат утонченный, деликатный, характерный водочный<br>\nВкус мягкий, чистый, с тонкими нюансами спельты и продолжительным согревающим послевкусием",
        "article": 97096,
        "uuid": "0d2c5185-f804-11ef-bba5-3cecef676e4f",
        "new": false
    },
    "variants": null
}
```
  

